{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0400fe7-1e50-481d-bb7e-62f2c126d4c2",
   "metadata": {},
   "source": [
    "# Aufgabe 3 - Tiefe Einblicke ins Institut: Reloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59687f3-c461-4f6e-a898-d023cdc8c67c",
   "metadata": {},
   "source": [
    "Den Code immer nachvollziehbar kommentieren! Bitte beachtet, dass das Notebook von Anfang bis Ende ohne Fehler durchlaufen muss und dass die requirements.txt Datei aktualisiert wird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48e97f2a-c3df-4121-8b13-eb35a1e77435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:31.578854100Z",
     "start_time": "2023-07-25T11:27:31.520057200Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  \n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EARLY_STOP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f0020-55eb-4023-a883-90ac6206cfb3",
   "metadata": {},
   "source": [
    "## Teilaufgabe a): Trainings-, Test-und Validierungsdatenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c91f492-e05c-4a7f-9a1c-8674e2ed71d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:31.626994100Z",
     "start_time": "2023-07-25T11:27:31.543778800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "random.seed(322)\n",
    "\n",
    "training_path_list = []     # Gleiche Liste aus Aufgabe 2\n",
    "test_path_list = []         # Gleiche Liste aus Aufgabe 2\n",
    "validation_path_list = []   # [\"./pfad/zu/bildZ.png\",\"./pfad/zu/bildY.png\",...]\n",
    "\n",
    "\n",
    "RE_FILE = re.compile(r\"[a-zA-Z]+\\d+\\.jpg\")\n",
    "\n",
    "\n",
    "def create_data_split(folder, label: int, train_percent, test_percent, val_percent, base_only=True):\n",
    "    \"\"\"\n",
    "    :param base_only: Only include base files, no augmented ones\n",
    "    \"\"\"\n",
    "\n",
    "    assert train_percent + test_percent == 1, \"train and test percentages dont add up to 1.0\"\n",
    "    assert 0 < val_percent <= 1, \"validation percent must be within [0..1]\"\n",
    "    files = os.listdir(folder)\n",
    "    if base_only:\n",
    "        files = [f for f in files if RE_FILE.match(f)]\n",
    "    random.shuffle(files)\n",
    "\n",
    "    train_cnt = math.ceil(len(files) * train_percent)\n",
    "    val_cnt = math.ceil(train_cnt * val_percent)\n",
    "    train_files = [f'{folder}/{f}' for f in files[:train_cnt]]\n",
    "    test_files = [f'{folder}/{f}' for f in files[train_cnt:]]\n",
    "    valid_files = train_files[:val_cnt]\n",
    "\n",
    "    random.shuffle(train_files)\n",
    "    random.shuffle(test_files)\n",
    "    random.shuffle(valid_files)\n",
    "\n",
    "    return list(zip(train_files, [label] * len(train_files))), \\\n",
    "           list(zip(test_files, [label] * len(test_files))), \\\n",
    "           list(zip(valid_files, [label] * len(valid_files)))\n",
    "\n",
    "\n",
    "def create_full_data_split(base_only=True):\n",
    "    train_percent = 0.7\n",
    "    test_percent = 0.3\n",
    "    val_percent = 0.3\n",
    "\n",
    "    flur_train, flur_test, flur_val = create_data_split('Bilder/Flur', 0, train_percent, test_percent, val_percent, base_only)\n",
    "    labo_train, labo_test, labo_val = create_data_split('Bilder/Labor', 1, train_percent, test_percent, val_percent, base_only)\n",
    "    prof_train, prof_test, prof_val = create_data_split('Bilder/Professorenbuero', 2, train_percent, test_percent, val_percent, base_only)\n",
    "    teek_train, teek_test, teek_val = create_data_split('Bilder/Teekueche', 3, train_percent, test_percent, val_percent, base_only)\n",
    "\n",
    "\n",
    "    train_files = flur_train + labo_train + prof_train + teek_train\n",
    "    test_files  = flur_test + labo_test + prof_test + teek_test\n",
    "    val_files   = flur_val + labo_val + prof_val + teek_val\n",
    "\n",
    "    random.shuffle(train_files)\n",
    "    random.shuffle(test_files)\n",
    "    random.shuffle(val_files)\n",
    "\n",
    "    train_batch_len = (len(train_files) // 16) * 16\n",
    "    test_batch_len = (len(test_files) // 16) * 16\n",
    "    val_batch_len = (len(val_files) // 16) * 16\n",
    "\n",
    "    return (\n",
    "        [f[0] for f in train_files][:train_batch_len],\n",
    "        [f[1] for f in train_files][:train_batch_len],\n",
    "        [f[0] for f in test_files][:test_batch_len],\n",
    "        [f[1] for f in test_files][:test_batch_len],\n",
    "        [f[0] for f in val_files][:val_batch_len],\n",
    "        [f[1] for f in val_files][:val_batch_len],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "training_path_list, y_train, test_path_list, y_test, validation_path_list, y_val = create_full_data_split()\n",
    "\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c6c68-033e-4d57-ba02-fc86c53f34f1",
   "metadata": {},
   "source": [
    "## Teilaufgabe b): CNN definieren und implementieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f484794-3ab2-4edf-84e4-8debf29b1d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:31.627993600Z",
     "start_time": "2023-07-25T11:27:31.571335500Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 3 input Kanäle (rgb) und führt 6 kernel der Größe 5x5 darauf aus\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # Eine kleine pooling layer verringert die Bildgröße und erzeugt ein wenig Translationsinvarianz\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 3. convolutional layer, welche auf die 6 Kanäle 16x einen 5x5 Kernel darauf ausführt\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Nach der convolutional Vorverarbeitung kommen dann noch 3 fully connected layer, welche die Anzahl der Neuronen stückweise auf die 4 gewünschten Label\n",
    "        # reduzieren\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "        # Dies ist eine klassische Architektur zur Verarbeitung von Bildern, welche sich bereits häufig bewährt hat\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb17fba-193f-4873-a631-7a902bb54675",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Teilaufgabe c): Training und Test mit CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369c7d9-bb8e-4856-943e-317067000bb7",
   "metadata": {},
   "source": [
    "Datenset-Klasse um mit Pytorch Bilder zu laden. \n",
    "\n",
    "Input sind: \n",
    "- Liste mit Pfaden zu Bildern\n",
    "- Liste mit dazugehörigen Labels (numerisch darstellen!) \n",
    "- Transformation der Bilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3b2967c-06da-4bda-a6a6-a0994d92bdc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:31.628492700Z",
     "start_time": "2023-07-25T11:27:31.583859200Z"
    }
   },
   "outputs": [],
   "source": [
    "class ROBDataset(Dataset):\n",
    "    def __init__(self, img_path_list, img_labels, transform=None):\n",
    "        # Pfade zu den Bildern als list\n",
    "        self.img_path_list = img_path_list\n",
    "        \n",
    "        # Dazugehörige Labels zu den Bildern als list\n",
    "        self.img_labels = img_labels\n",
    "        \n",
    "        # Transformations der Bilder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Bild laden\n",
    "        img_path = self.img_path_list[idx]\n",
    "        image = read_image(img_path)\n",
    "        \n",
    "        # Label laden\n",
    "        label = self.img_labels[idx]\n",
    "        \n",
    "        # Transformieren\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image.float(), int(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8928b-daf3-459e-a540-aa98944b18e3",
   "metadata": {},
   "source": [
    "Trainingsiteration über alle Bilder.\n",
    "\n",
    "Inputs sind:\n",
    "- Pytorch dataloader Object über das iteriert wird\n",
    "- bool do_backprob Parameter um Backpropagation durchzuführen oder nicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaaff24b-78a7-4701-915d-0e271402f70a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:31.628992700Z",
     "start_time": "2023-07-25T11:27:31.600947300Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "def accuracy_score(output, labels):\n",
    "    output = torch.from_numpy(output)\n",
    "    labels = torch.from_numpy(labels)\n",
    "    acc = Accuracy(task=\"multiclass\", num_classes=4)\n",
    "    r = acc(output, labels)\n",
    "    return r\n",
    "\n",
    "# Iterating over the entire data set once\n",
    "def run_iteration(dataloader, do_backprob=True):\n",
    "    global net, optimizer, criterion\n",
    "    loss_iter = []\n",
    "    acc_iter = []\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        # To device\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        y_predict = net(batch_x)\n",
    "        loss = criterion(y_predict, batch_y)\n",
    "        if do_backprob:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        loss_iter.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "        _, predicted = torch.max(torch.softmax(y_predict, dim=1),1)\n",
    "        \n",
    "        acc_iter.append(accuracy_score(batch_y.detach().cpu().numpy(), \n",
    "                                       predicted.detach().cpu().numpy()))\n",
    "    \n",
    "    return np.mean(loss_iter), np.mean(acc_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e616ae6-75e5-42a1-be39-d914424fe62d",
   "metadata": {},
   "source": [
    "Komplette Durchführung eines Trainings\n",
    "Die Variablen y_train, y_val und y_test müssen noch gesetzt werden. Diese Listen beinhalten die entsprechenden Labels als numerische Darstellung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found DirectML\n"
     ]
    }
   ],
   "source": [
    "# Get the device. This adds support for DirectML as I have an AMD GPU, which is a giant pain for machine learning (*cries over awful ROCm installation instructions*)\n",
    "try:\n",
    "    import torch_directml\n",
    "    device = torch_directml.device()\n",
    "    print('Found DirectML')\n",
    "except ModuleNotFoundError:\n",
    "    print('No DirectML found. Using CUDA / CPU instead')\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:31.629493Z",
     "start_time": "2023-07-25T11:27:31.614973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c918f-85f4-48b5-a089-4215da53b075",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-25T11:28:24.425558200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  privateuseone:0\n",
      "Train / test images: 208/80\n",
      "\n",
      "Started Training\n",
      "Epoch 1 from 100\n",
      "\tTrain Loss\t 1.3664448\n",
      "\tTrain Acc.\t 0.3028846\n",
      "\tVal Loss\t 1.1918812\n",
      "\tVal Acc.\t 0.546875\n",
      "\tDiff\t\t 0.17456364631652832\n",
      "Epoch 2 from 100\n",
      "\tTrain Loss\t 0.98376757\n",
      "\tTrain Acc.\t 0.5576923\n",
      "\tVal Loss\t 0.7661413\n",
      "\tVal Acc.\t 0.65625\n",
      "\tDiff\t\t 0.21762627363204956\n",
      "Epoch 3 from 100\n",
      "\tTrain Loss\t 0.63183373\n",
      "\tTrain Acc.\t 0.75\n",
      "\tVal Loss\t 0.47996184\n",
      "\tVal Acc.\t 0.828125\n",
      "\tDiff\t\t 0.15187188982963562\n",
      "Epoch 4 from 100\n",
      "\tTrain Loss\t 0.33849594\n",
      "\tTrain Acc.\t 0.8942308\n",
      "\tVal Loss\t 0.38563395\n",
      "\tVal Acc.\t 0.859375\n",
      "\tDiff\t\t 0.04713800549507141\n",
      "Epoch 5 from 100\n",
      "\tTrain Loss\t 0.30453917\n",
      "\tTrain Acc.\t 0.9230769\n",
      "\tVal Loss\t 0.120399185\n",
      "\tVal Acc.\t 0.984375\n",
      "\tDiff\t\t 0.18413999676704407\n",
      "Epoch 6 from 100\n",
      "\tTrain Loss\t 0.1458144\n",
      "\tTrain Acc.\t 0.94711536\n",
      "\tVal Loss\t 0.14456443\n",
      "\tVal Acc.\t 0.9375\n",
      "\tDiff\t\t 0.0012499690055847168\n",
      "Epoch 7 from 100\n",
      "\tTrain Loss\t 0.09278503\n",
      "\tTrain Acc.\t 0.96634614\n",
      "\tVal Loss\t 0.03328934\n",
      "\tVal Acc.\t 0.984375\n",
      "\tDiff\t\t 0.05949569121003151\n",
      "Epoch 8 from 100\n",
      "\tTrain Loss\t 0.024782946\n",
      "\tTrain Acc.\t 0.9951923\n",
      "\tVal Loss\t 0.014900338\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 0.00988260842859745\n",
      "Epoch 9 from 100\n",
      "\tTrain Loss\t 0.005034829\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.0022277567\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 0.00280707236379385\n",
      "Epoch 10 from 100\n",
      "\tTrain Loss\t 0.0020251854\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.0007916161\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 0.0012335693463683128\n",
      "Epoch 11 from 100\n",
      "\tTrain Loss\t 0.0009603318\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.0006214404\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 0.0003388914046809077\n",
      "Epoch 12 from 100\n",
      "\tTrain Loss\t 0.000633973\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00043673642\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 0.00019723657169379294\n",
      "Epoch 13 from 100\n",
      "\tTrain Loss\t 0.00043909825\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.0003625317\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 7.656656089238822e-05\n",
      "Epoch 14 from 100\n",
      "\tTrain Loss\t 0.00036664977\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00031858444\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 4.806532524526119e-05\n",
      "Epoch 15 from 100\n",
      "\tTrain Loss\t 0.00031403705\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.0002697176\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 4.431945853866637e-05\n",
      "Epoch 16 from 100\n",
      "\tTrain Loss\t 0.00027327143\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00023399977\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 3.927166108042002e-05\n",
      "Epoch 17 from 100\n",
      "\tTrain Loss\t 0.00023832082\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00020449185\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 3.3828968298621476e-05\n",
      "Epoch 18 from 100\n",
      "\tTrain Loss\t 0.00021088836\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00018266763\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.8220732929185033e-05\n",
      "Epoch 19 from 100\n",
      "\tTrain Loss\t 0.00018719227\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00016398958\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.3202694137580693e-05\n",
      "Epoch 20 from 100\n",
      "\tTrain Loss\t 0.00016883785\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00014807821\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.0759645849466324e-05\n",
      "Epoch 21 from 100\n",
      "\tTrain Loss\t 0.00015258828\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.0001311204\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.146788756363094e-05\n",
      "Epoch 22 from 100\n",
      "\tTrain Loss\t 0.00013899029\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00011846489\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.052539639407769e-05\n",
      "Epoch 23 from 100\n",
      "\tTrain Loss\t 0.00012540292\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.000109587214\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 1.5815705410204828e-05\n",
      "Epoch 24 from 100\n",
      "\tTrain Loss\t 0.00011450552\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 0.00010296646\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 1.1539057595655322e-05\n",
      "Epoch 25 from 100\n",
      "\tTrain Loss\t 0.000106236235\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 9.410719e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 1.2129043170716614e-05\n",
      "Epoch 26 from 100\n",
      "\tTrain Loss\t 9.7651864e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 8.6338e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 1.1313866707496345e-05\n",
      "Epoch 27 from 100\n",
      "\tTrain Loss\t 9.099226e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 7.968115e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 1.131110911956057e-05\n",
      "Epoch 28 from 100\n",
      "\tTrain Loss\t 8.426608e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 7.535025e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 8.915827493183315e-06\n",
      "Epoch 29 from 100\n",
      "\tTrain Loss\t 7.8427125e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 7.003342e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 8.393704774789512e-06\n",
      "Epoch 30 from 100\n",
      "\tTrain Loss\t 7.332905e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 6.6097426e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 7.231625204440206e-06\n",
      "Epoch 31 from 100\n",
      "\tTrain Loss\t 6.8809146e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 6.128871e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 7.520437065977603e-06\n",
      "Epoch 32 from 100\n",
      "\tTrain Loss\t 6.482221e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 5.7749126e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 7.0730857260059565e-06\n",
      "Epoch 33 from 100\n",
      "\tTrain Loss\t 6.087169e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 5.4418135e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 6.453556125052273e-06\n",
      "Epoch 34 from 100\n",
      "\tTrain Loss\t 5.759791e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 5.17033e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 5.894609785173088e-06\n",
      "Epoch 35 from 100\n",
      "\tTrain Loss\t 5.416232e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 4.888239e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 5.279929609969258e-06\n",
      "Epoch 36 from 100\n",
      "\tTrain Loss\t 5.1311785e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 4.6493322e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 4.818462912226096e-06\n",
      "Epoch 37 from 100\n",
      "\tTrain Loss\t 4.8776892e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 4.4258828e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 4.518064088188112e-06\n",
      "Epoch 38 from 100\n",
      "\tTrain Loss\t 4.6299345e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 4.1631527e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 4.667817847803235e-06\n",
      "Epoch 39 from 100\n",
      "\tTrain Loss\t 4.397934e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 3.9650204e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 4.329136572778225e-06\n",
      "Epoch 40 from 100\n",
      "\tTrain Loss\t 4.2121657e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 3.8188373e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 3.9332844607997686e-06\n",
      "Epoch 41 from 100\n",
      "\tTrain Loss\t 4.013272e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 3.6404428e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 3.7282916309777647e-06\n",
      "Epoch 42 from 100\n",
      "\tTrain Loss\t 3.8234924e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 3.5022655e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 3.212269803043455e-06\n",
      "Epoch 43 from 100\n",
      "\tTrain Loss\t 3.6468897e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 3.3369015e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 3.0998817237559706e-06\n",
      "Epoch 44 from 100\n",
      "\tTrain Loss\t 3.4973873e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 3.1721018e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 3.25285509461537e-06\n",
      "Epoch 45 from 100\n",
      "\tTrain Loss\t 3.3494933e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 3.0430496e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 3.064436896238476e-06\n",
      "Epoch 46 from 100\n",
      "\tTrain Loss\t 3.1985015e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 2.922931e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.7557052817428485e-06\n",
      "Epoch 47 from 100\n",
      "\tTrain Loss\t 3.0785035e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 2.846013e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.3249049263540655e-06\n",
      "Epoch 48 from 100\n",
      "\tTrain Loss\t 2.9483683e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 2.7208705e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.274977305205539e-06\n",
      "Epoch 49 from 100\n",
      "\tTrain Loss\t 2.8364542e-05\n",
      "\tTrain Acc.\t 1.0\n",
      "\tVal Loss\t 2.5940513e-05\n",
      "\tVal Acc.\t 1.0\n",
      "\tDiff\t\t 2.4240289349108934e-06\n",
      "Epoch 50 from 100\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Training settings - bei Bedarf anpassbar\n",
    "max_epoch = 100\n",
    "batch_size = 16\n",
    "lr = 0.001\n",
    "early_stop_cnt = 0\n",
    "early_stop_min_delta = 0.000001\n",
    "early_stop_tolerance = 5\n",
    "\n",
    "# Transformations for dataloader\n",
    "t_train = T.Compose([T.ToPILImage(),\n",
    "                   T.ToTensor(),\n",
    "                   T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "t_val = T.Compose([T.ToPILImage(),\n",
    "                   T.ToTensor(),\n",
    "                   T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "t_test = T.Compose([T.ToPILImage(),\n",
    "                   T.ToTensor(),\n",
    "                   T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "# Where to do calculations\n",
    "print(\"Running on \", device)\n",
    "print(f'Train / test images: {len(training_path_list)}/{len(test_path_list)}')\n",
    "\n",
    "# Training Data, NOTE: y_train labels need to be set\n",
    "dataset_train = ROBDataset(training_path_list, y_train, transform=t_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Validation Data, NOTE: y_val labels need to be set\n",
    "dataset_val = ROBDataset(validation_path_list, y_val, transform=t_train)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Test Data, NOTE: y_test labels need. to be set\n",
    "dataset_test = ROBDataset(test_path_list, y_test,transform=t_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Network, optimizer and loss initialisation\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Los geht's mit Training\n",
    "print(\"\\nStarted Training\")\n",
    "# Training loss and accuracy per epoch\n",
    "train_loss_epoch = []\n",
    "train_acc_epoch = []\n",
    "# Validation loss and accuracy per epoch\n",
    "val_loss_epoch = []\n",
    "val_acc_epoch = []\n",
    "\n",
    "t1 = time.time()\n",
    "for epoch in range(0,max_epoch):  # loop over the dataset multiple times\n",
    "    print(f\"Epoch {epoch+1} from {max_epoch}\")\n",
    "    \n",
    "    ### TRAINING ###\n",
    "    net.train()\n",
    "    train_loss_iter, train_acc_iter = run_iteration(dataloader_train)\n",
    "\n",
    "    # Logging loss and accuarcy of training iteration\n",
    "    train_loss_epoch.append(train_loss_iter)\n",
    "    train_acc_epoch.append(train_acc_iter)\n",
    "    print(\"\\tTrain Loss\\t\",train_loss_iter)\n",
    "    print(\"\\tTrain Acc.\\t\",train_acc_iter)\n",
    "    \n",
    "    ### VALIDATION ###\n",
    "    with torch.no_grad():  # No gradient calculation\n",
    "        net.eval()\n",
    "        val_loss_iter, val_acc_iter = run_iteration(dataloader_val,do_backprob=False)\n",
    "\n",
    "        # Logging loss and accuarcy of validation iteration\n",
    "        val_loss_epoch.append(val_loss_iter)\n",
    "        val_acc_epoch.append(val_acc_iter)\n",
    "        print(\"\\tVal Loss\\t\",val_loss_iter)\n",
    "        print(\"\\tVal Acc.\\t\",val_acc_iter)\n",
    "\n",
    "    if EARLY_STOP:\n",
    "        loss_diff = abs(val_loss_iter - train_loss_iter)\n",
    "        print(f'\\tDiff\\t\\t {loss_diff}')\n",
    "        if loss_diff < early_stop_min_delta:\n",
    "            early_stop_cnt += 1\n",
    "            if early_stop_cnt >= early_stop_tolerance:\n",
    "                print(f\"[EARLY STOP] Reached early stop at epoch {epoch}.\")\n",
    "                break\n",
    "\n",
    "\n",
    "print(f'Training took {round(time.time() - t1)}s')\n",
    "\n",
    "# Plotting results\n",
    "fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(10,3))\n",
    "ax[0].plot(train_loss_epoch,label=\"Train\")\n",
    "ax[0].plot(val_loss_epoch,label=\"Val\",linestyle=\"-.\")\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(train_acc_epoch,label=\"Train\")\n",
    "ax[1].plot(val_acc_epoch,label=\"Val\",linestyle=\"-.\")\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].legend()\n",
    "plt.savefig(\"loss_augmentation.png\",format=\"png\",bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0 0]\n",
      " [0 3 1 0]\n",
      " [0 1 3 0]\n",
      " [0 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Confusion matrix\n",
    "net.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader_test:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_predictions)\n",
    "print(conf_matrix)  # See first cell to know what each label corresponds to"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:55.578598300Z",
     "start_time": "2023-07-25T11:27:55.520835100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "51e14a88-cf54-40a0-b118-05e243e0b995",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Teilaufgabe d): Augmentierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65263759-2c02-43f0-b756-c8f8ad77b75e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:55.813642200Z",
     "start_time": "2023-07-25T11:27:55.570081Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Possible ways to augment the data would be to flip and rotate the images as well as add color filters like grayscale. Other possible techniques could be kernel filters (to change sharpness) or cropping the image\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "\n",
    "def make_grayscale(input_file: str, output_file: str):\n",
    "    image = Image.open(input_file)\n",
    "    grayscale_image = image.convert('L')\n",
    "    grayscale_image_3_chn = grayscale_image.convert('RGB')  # Must keep 3 channels\n",
    "    grayscale_image_3_chn.save(output_file)\n",
    "\n",
    "def flip_image(input_file: str, output_file: str):\n",
    "    image = Image.open(input_file)\n",
    "    flipped_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    flipped_image.save(output_file)\n",
    "\n",
    "\n",
    "# Create new images\n",
    "for folder in ('Flur', 'Labor', 'Professorenbuero', 'Teekueche'):\n",
    "    # Delete existing images\n",
    "    folder_path = f'Bilder/{folder}'\n",
    "    files = natsorted([f for f in os.listdir(folder_path) if RE_FILE.match(f)])\n",
    "    for i, file in enumerate(files):\n",
    "        make_grayscale(f'{folder_path}/{file}', f'{folder_path}/{folder}_gray_{i + 1}.jpg')\n",
    "        flip_image(f'{folder_path}/{file}', f'{folder_path}/{folder}_flipped_{i + 1}.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nDurch die Augmentierung steigert sich die Genauigkeit auf dem validation Datensatz auf 100%\\n'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify training / test / validation data\n",
    "training_path_list, y_train, test_path_list, y_test, validation_path_list, y_val = create_full_data_split(base_only=False)\n",
    "\n",
    "# Now run the training cell again\n",
    "\n",
    "\"\"\"\n",
    "Durch die Augmentierung steigert sich die Genauigkeit auf dem validation Datensatz auf 100%\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:55.829678600Z",
     "start_time": "2023-07-25T11:27:55.816456500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "ba0cffb4-b4dd-4df8-b7d5-f2f98c8a698b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Teilaufgabe e): Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a72c1da-07de-4252-a4a9-b373918b1cf2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-25T11:27:55.874820500Z",
     "start_time": "2023-07-25T11:27:55.830675800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nDurch das early stop wird das Training vorzeitig beendet und die Trainingsphase dauert weniger lange, ergibt aber ein Model mit der gleichen Genauigkeit\\n'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EARLY_STOP = True\n",
    "\n",
    "# Now run the training cell again\n",
    "\n",
    "\"\"\"\n",
    "Durch das early stop wird das Training vorzeitig beendet und die Trainingsphase dauert weniger lange, ergibt aber ein Model mit der gleichen Genauigkeit\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
